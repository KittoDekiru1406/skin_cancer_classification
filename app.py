"""
FastAPI Backend cho h·ªá th·ªëng ch·∫©n ƒëo√°n b·ªánh ngo√†i da
Refactored v·ªõi proper structure, type hints v√† docstrings
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from typing import Dict, List, Any
from contextlib import asynccontextmanager
import logging

# Import c√°c modules ƒë√£ refactor
from models.schemas import (
    HealthCheckResponse,
    AvailableModelsResponse,
    ModelPredictionResponse, 
    AllModelsPredictionResponse,
    ErrorResponse,
    ModelInfo
)
from services.prediction_service import prediction_service
from utils.model_utils import model_manager
from config.settings import API_CONFIG, DISEASE_INFO_MAP

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Lifespan event handler - replaces on_event startup/shutdown
    """
    # Startup
    try:
        logger.info("üöÄ Starting Skin Cancer Classification API...")
        
        # Load t·∫•t c·∫£ models
        weights_dir = "weights"
        loaded_models = model_manager.load_all_models(weights_dir)
        
        if not loaded_models:
            logger.warning("‚ö†Ô∏è No models were loaded! Please check the weights directory.")
            logger.info("üí° Make sure you have model files in weights/ directory:")
            logger.info("   - weights/mobilenet/final_mobilenet_skin_cancer_model.h5")
            logger.info("   - weights/self_build/model.h5") 
            logger.info("   - weights/resnet50/resnet50_skin_cancer_model.pkl")
        
        logger.info("‚úÖ API startup completed!")
        
    except Exception as e:
        logger.error(f"‚ùå Error during startup: {str(e)}")
    
    yield
    
    # Shutdown (if needed)
    logger.info("üõë Shutting down Skin Cancer Classification API...")


# T·∫°o FastAPI app v·ªõi lifespan
app = FastAPI(
    title=API_CONFIG['title'],
    description=API_CONFIG['description'],
    version=API_CONFIG['version'],
    lifespan=lifespan
)

# C·∫•u h√¨nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/", response_model=HealthCheckResponse)
async def health_check() -> HealthCheckResponse:
    """
    Health check endpoint
    
    Returns:
        HealthCheckResponse: Status c·ªßa h·ªá th·ªëng
    """
    available_models = list(model_manager.get_all_models().keys())
    
    return HealthCheckResponse(
        message="üè• Skin Cancer Classification API", 
        status="healthy",
        available_models=available_models
    )


@app.get("/models", response_model=AvailableModelsResponse)
async def get_available_models() -> AvailableModelsResponse:
    """
    L·∫•y danh s√°ch models c√≥ s·∫µn
    
    Returns:
        AvailableModelsResponse: Th√¥ng tin c√°c models c√≥ s·∫µn
    """
    available_models = model_manager.get_all_models()
    
    model_info = {}
    for model_name in available_models.keys():
        model_info[model_name] = ModelInfo(
            name=model_name.replace('_', ' ').title(),
            status="loaded"
        )
    
    # Debug info
    logger.info(f"Available models: {list(available_models.keys())}")
    
    return AvailableModelsResponse(
        available_models=model_info,
        total_models=len(available_models),
        model_names=list(available_models.keys())
    )


@app.get("/disease-info")
async def get_disease_info() -> Dict[str, Any]:
    """
    L·∫•y th√¥ng tin v·ªÅ c√°c lo·∫°i b·ªánh
    
    Returns:
        Dict: Th√¥ng tin chi ti·∫øt v·ªÅ c√°c lo·∫°i b·ªánh
    """
    return {"disease_info": DISEASE_INFO_MAP}


@app.post("/predict/{model_name}", response_model=ModelPredictionResponse)
async def predict_single_model(
    model_name: str,
    file: UploadFile = File(...)
) -> ModelPredictionResponse:
    """
    D·ª± ƒëo√°n v·ªõi m·ªôt model c·ª• th·ªÉ
    
    Args:
        model_name: T√™n model (mobilenet, resnet50, self_build)
        file: File ·∫£nh upload
        
    Returns:
        ModelPredictionResponse: K·∫øt qu·∫£ d·ª± ƒëo√°n
        
    Raises:
        HTTPException: N·∫øu c√≥ l·ªói trong qu√° tr√¨nh d·ª± ƒëo√°n
    """
    # Ki·ªÉm tra file type (relaxed validation)
    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff')
    filename_lower = (file.filename or "").lower()
    
    # Check both content type and file extension
    is_valid_content = file.content_type and file.content_type.startswith('image/')
    is_valid_extension = any(filename_lower.endswith(ext) for ext in valid_extensions)
    
    if not (is_valid_content or is_valid_extension):
        raise HTTPException(
            status_code=400, 
            detail=f"File ph·∫£i l√† ·∫£nh. Supported formats: {', '.join(valid_extensions)}"
        )
    
    try:
        # ƒê·ªçc ·∫£nh
        image_data = await file.read()
        
        # D·ª± ƒëo√°n
        result = prediction_service.predict_single_model(
            image_data=image_data,
            filename=file.filename or "unknown",
            model_name=model_name
        )
        
        return result
        
    except ValueError as e:
        logger.error(f"‚ùå Validation error: {str(e)}")
        raise HTTPException(status_code=404, detail=str(e))
    
    except Exception as e:
        logger.error(f"‚ùå Prediction error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"L·ªói server: {str(e)}")


@app.post("/predict/all", response_model=AllModelsPredictionResponse)
async def predict_all_models(
    file: UploadFile = File(...)
) -> AllModelsPredictionResponse:
    """
    D·ª± ƒëo√°n v·ªõi t·∫•t c·∫£ models c√≥ s·∫µn
    
    Args:
        file: File ·∫£nh upload
        
    Returns:
        AllModelsPredictionResponse: K·∫øt qu·∫£ t·ª´ t·∫•t c·∫£ models
        
    Raises:
        HTTPException: N·∫øu c√≥ l·ªói trong qu√° tr√¨nh d·ª± ƒëo√°n
    """
    # Ki·ªÉm tra file type (relaxed validation)
    valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff')
    filename_lower = (file.filename or "").lower()
    
    # Check both content type and file extension
    is_valid_content = file.content_type and file.content_type.startswith('image/')
    is_valid_extension = any(filename_lower.endswith(ext) for ext in valid_extensions)
    
    if not (is_valid_content or is_valid_extension):
        raise HTTPException(
            status_code=400, 
            detail=f"File ph·∫£i l√† ·∫£nh. Supported formats: {', '.join(valid_extensions)}"
        )
    
    # Ki·ªÉm tra c√≥ models kh√¥ng
    available_models = model_manager.get_all_models()
    if not available_models:
        raise HTTPException(status_code=503, detail="Kh√¥ng c√≥ model n√†o ƒë∆∞·ª£c load")
    
    try:
        # ƒê·ªçc ·∫£nh
        image_data = await file.read()
        
        # D·ª± ƒëo√°n v·ªõi t·∫•t c·∫£ models
        result = prediction_service.predict_all_models(
            image_data=image_data,
            filename=file.filename or "unknown"
        )
        
        return result
        
    except ValueError as e:
        logger.error(f"‚ùå Validation error: {str(e)}")
        raise HTTPException(status_code=400, detail=str(e))
    
    except Exception as e:
        logger.error(f"‚ùå Prediction error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"L·ªói server: {str(e)}")



@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """
    Global exception handler
    """
    logger.error(f"‚ùå Unhandled exception: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={"detail": "Internal server error"}
    )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app, 
        host=API_CONFIG['host'], 
        port=API_CONFIG['port']
    )
